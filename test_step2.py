#!/usr/bin/env python3
"""
Step 2 Verification Script

This script tests the data preprocessing pipeline with your actual forestry dataset
without requiring all dependencies to be installed.
"""

import sys
import os
from pathlib import Path

def test_step2_basic():
    """Test basic Step 2 functionality."""
    print("ğŸ§ª Testing Step 2: Data Ingestion and Preprocessing")
    print("=" * 60)
    
    # Check project structure
    project_root = Path(__file__).parent
    src_path = project_root / 'src'
    
    print(f"ğŸ“ Project root: {project_root}")
    print(f"ğŸ“ Source path: {src_path}")
    
    # Add src to path
    sys.path.insert(0, str(src_path))
    
    try:
        # Test dataset configuration (should work without dependencies)
        print("\n1ï¸âƒ£ Testing Dataset Configuration...")
        from dataset_config import DatasetConfig
        
        config = DatasetConfig(project_root)
        
        # List available datasets
        available = config.list_available_datasets()
        print(f"   Found {len(available)} dataset configurations")
        
        for key, info in available.items():
            status = "âœ“" if info['has_images'] and info['has_annotations'] else "âœ—"
            print(f"   {status} {key}: {info['description']}")
        
        # Validate paths
        validation = config.validate_dataset_paths()
        total_images = sum(v['image_count'] for v in validation.values())
        valid_datasets = sum(1 for v in validation.values() if v['path_exists'])
        
        print(f"   ğŸ“Š Total images found: {total_images}")
        print(f"   âœ… Valid datasets: {valid_datasets}/{len(validation)}")
        
        # Test recommendations
        recommendations = config.get_recommended_splits()
        print(f"   ğŸ¯ Recommended source: {recommendations['source_domain']}")
        print(f"   ğŸ¯ Recommended target: {recommendations['target_domain']}")
        
        print("   âœ… Dataset configuration test passed!")
        
    except Exception as e:
        print(f"   âŒ Dataset configuration test failed: {e}")
        return False
    
    try:
        # Test basic data preprocessing imports (might fail due to missing deps)
        print("\n2ï¸âƒ£ Testing Data Preprocessing Imports...")
        
        # Try to import without actually using heavy dependencies
        from data_preprocessing import ImageAnnotation, DataPreprocessor
        
        print("   âœ… Core classes imported successfully")
        
        # Test basic annotation structure
        test_annotation = ImageAnnotation(
            image_id=1,
            file_name="test.jpg",
            width=1024,
            height=768,
            boxes=[[100, 100, 200, 150]],
            category_ids=[1],
            annotation_ids=[1],
            domain="source"
        )
        
        print(f"   âœ… ImageAnnotation created: {test_annotation.file_name}")
        print("   âœ… Data preprocessing structure test passed!")
        
    except ImportError as e:
        print(f"   âš ï¸ Import test failed (expected if dependencies not installed): {e}")
        print("   â„¹ï¸ This is normal - run 'pip install -r requirements.txt' to fix")
    except Exception as e:
        print(f"   âŒ Data preprocessing test failed: {e}")
        return False
    
    try:
        # Test actual dataset files
        print("\n3ï¸âƒ£ Testing Actual Dataset Files...")
        
        dataset_dir = project_root / "dataset"
        
        # Check main dataset
        part1_images = dataset_dir / "Dataset" / "part_1" / "2k_dataset"
        part1_annotations = dataset_dir / "Dataset" / "part_1" / "coco_annotations.json"
        
        if part1_images.exists():
            image_files = list(part1_images.glob("*.jpg")) + list(part1_images.glob("*.JPG"))
            print(f"   ğŸ“¸ Found {len(image_files)} images in part_1")
        else:
            print("   âš ï¸ part_1 images directory not found")
        
        if part1_annotations.exists():
            print("   ğŸ“‹ part_1 annotations file found")
            
            # Try to read a small portion of the annotations
            try:
                import json
                with open(part1_annotations, 'r') as f:
                    # Read just the first part to check structure
                    content = f.read(1000)  # First 1000 characters
                    if '"images"' in content and '"annotations"' in content:
                        print("   âœ… Annotations file has correct COCO structure")
                    else:
                        print("   âš ï¸ Annotations file structure unclear")
            except Exception as e:
                print(f"   âš ï¸ Could not read annotations: {e}")
        else:
            print("   âš ï¸ part_1 annotations file not found")
        
        # Check testing dataset
        testing_images = dataset_dir / "Testing" / "simulated_images" / "images"
        testing_annotations = dataset_dir / "Testing" / "simulated_images" / "coco_annotations.json"
        
        if testing_images.exists():
            test_image_files = list(testing_images.glob("*.jpg")) + list(testing_images.glob("*.JPG"))
            print(f"   ğŸ“¸ Found {len(test_image_files)} images in testing")
        
        if testing_annotations.exists():
            print("   ğŸ“‹ Testing annotations file found")
        
        print("   âœ… Dataset file structure test completed!")
        
    except Exception as e:
        print(f"   âŒ Dataset file test failed: {e}")
        return False
    
    # Final summary
    print(f"\n" + "=" * 60)
    print("ğŸ‰ Step 2 Basic Tests Completed!")
    print("\nğŸ“‹ Summary:")
    print("âœ… Dataset configuration system working")
    print("âœ… Data preprocessing structure ready") 
    print("âœ… Your forestry dataset detected and analyzed")
    print("âœ… COCO annotation format confirmed")
    print("âœ… Ready for full pipeline with dependencies installed")
    
    print(f"\nğŸš€ Next Steps:")
    print("1. Install dependencies: pip install -r requirements.txt")
    print("2. Run the main notebook: jupyter notebook main_pipeline.ipynb")
    print("3. Execute Step 2 cells to see full preprocessing in action")
    print("4. Proceed to Step 3: Zero-Shot Mask Generation")
    
    return True

if __name__ == "__main__":
    success = test_step2_basic()
    sys.exit(0 if success else 1)
