{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f016700c",
   "metadata": {},
   "source": [
    "# SAM-based Segmentation with Domain Adaptation Pipeline\n",
    "\n",
    "This notebook implements a comprehensive segmentation pipeline using the Segment Anything Model (SAM) with domain adaptation for generalized object segmentation from bounding boxes.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **Environment Setup** - Verify dependencies, CUDA, and SAM model\n",
    "2. **Data Ingestion** - Load and preprocess datasets\n",
    "3. **Zero-Shot Segmentation** - Generate initial masks with SAM\n",
    "4. **Feature Extraction** - Extract features for domain adaptation\n",
    "5. **Domain Alignment** - Unsupervised domain adaptation\n",
    "6. **Self-Training** - Iterative improvement on target domain\n",
    "7. **Post-Processing** - CRF and morphological refinement\n",
    "8. **Evaluation** - Validation and performance metrics\n",
    "9. **Inference Pipeline** - Final deployment-ready pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb832a",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "First, let's set up the environment and verify all dependencies are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58530a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to Python path\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get project root directory\n",
    "project_root = Path.cwd()\n",
    "if project_root.name != 'SMGwithDA':\n",
    "    project_root = project_root.parent\n",
    "\n",
    "# Add src directory to path\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Source path: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import environment setup module\n",
    "from environment_setup import EnvironmentSetup\n",
    "\n",
    "# Initialize environment setup\n",
    "env_setup = EnvironmentSetup(project_root=project_root)\n",
    "\n",
    "# Run complete setup (this will take some time for first run)\n",
    "print(\"Starting environment setup...\")\n",
    "print(\"This may take several minutes on first run (downloading SAM model)...\\n\")\n",
    "\n",
    "setup_success = env_setup.run_complete_setup(\n",
    "    download_sam=True,  # Download SAM checkpoint\n",
    "    sam_model='vit_b'   # Use base model (fastest, smallest)\n",
    ")\n",
    "\n",
    "if setup_success:\n",
    "    print(\"\\nüéâ Environment setup completed successfully!\")\n",
    "    print(\"Ready to proceed with the segmentation pipeline.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Environment setup encountered issues.\")\n",
    "    print(\"Please resolve the issues above before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d984148",
   "metadata": {},
   "source": [
    "### SAM Model Setup and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SAM setup module\n",
    "from sam_setup import SAMSetup, create_sam_setup\n",
    "\n",
    "# Create SAM setup instance\n",
    "print(\"Setting up SAM model...\")\n",
    "sam_setup = create_sam_setup(\n",
    "    model_type='vit_b',  # Base model for faster processing\n",
    "    device='auto'        # Automatically choose CUDA or CPU\n",
    ")\n",
    "\n",
    "# Display model information\n",
    "model_info = sam_setup.get_model_info()\n",
    "print(\"\\nSAM Model Information:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb5aa3",
   "metadata": {},
   "source": [
    "### Environment Summary\n",
    "\n",
    "Before proceeding to the next step, let's summarize the current setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deabdb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment summary\n",
    "print(\"=== ENVIRONMENT SETUP SUMMARY ===\")\n",
    "print(f\"‚úì Project root: {project_root}\")\n",
    "print(f\"‚úì Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check key directories\n",
    "directories = ['src', 'models', 'dataset', 'dataset/source', 'dataset/target']\n",
    "for dir_name in directories:\n",
    "    dir_path = project_root / dir_name\n",
    "    status = \"‚úì\" if dir_path.exists() else \"‚úó\"\n",
    "    print(f\"{status} Directory: {dir_name}\")\n",
    "\n",
    "# Check SAM model\n",
    "if sam_setup.sam_model is not None:\n",
    "    print(\"‚úì SAM model loaded and ready\")\n",
    "    print(f\"  Model type: {sam_setup.model_type}\")\n",
    "    print(f\"  Device: {sam_setup.device}\")\n",
    "else:\n",
    "    print(\"‚úó SAM model not loaded\")\n",
    "\n",
    "print(\"\\n=== NEXT STEPS ===\")\n",
    "print(\"1. Environment setup is complete\")\n",
    "print(\"2. Ready to proceed to Step 2: Data Ingestion and Preprocessing\")\n",
    "print(\"3. Place your dataset in the 'dataset/' directory before proceeding\")\n",
    "print(\"\\nProject structure:\")\n",
    "print(\"dataset/\")\n",
    "print(\"‚îú‚îÄ‚îÄ source/          # Source domain images and annotations\")\n",
    "print(\"‚îÇ   ‚îú‚îÄ‚îÄ images/\")\n",
    "print(\"‚îÇ   ‚îî‚îÄ‚îÄ annotations/\")\n",
    "‚îî‚îÄ‚îÄ target/          # Target domain images and annotations\")\n",
    "print(\"    ‚îú‚îÄ‚îÄ images/\")\n",
    "print(\"    ‚îî‚îÄ‚îÄ annotations/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833175e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1 Complete ‚úÖ\n",
    "\n",
    "**What we accomplished:**\n",
    "1. ‚úÖ Set up project directory structure\n",
    "2. ‚úÖ Verified CUDA/GPU availability\n",
    "3. ‚úÖ Checked all required dependencies\n",
    "4. ‚úÖ Downloaded and loaded SAM model checkpoint\n",
    "5. ‚úÖ Created environment setup utilities\n",
    "6. ‚úÖ Prepared SAM model for domain adaptation\n",
    "\n",
    "**Next Step:** Data Ingestion and Preprocessing\n",
    "\n",
    "Before proceeding, please:\n",
    "1. Place your dataset in the appropriate directories\n",
    "2. Ensure annotations are in the correct format\n",
    "3. Confirm the setup summary above shows all checkmarks (‚úì)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae0fe1",
   "metadata": {},
   "source": [
    "# SAM-based Segmentation with Domain Adaptation\n",
    "## Foundation Model‚ÄìBased Approach for Generalized Mask Generation\n",
    "\n",
    "This notebook implements a comprehensive pipeline for generating segmentation masks from bounding boxes using:\n",
    "- **SAM (Segment Anything Model)** as the foundation model\n",
    "- **Unsupervised Domain Adaptation** for generalization\n",
    "- **Self-training** for target domain adaptation\n",
    "\n",
    "**Target Use Case**: Cluttered forest environment datasets with bounding box annotations\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. **Environment Setup** - CUDA verification, dependencies, SAM initialization\n",
    "2. **Data Ingestion** - Source/target data loading and preprocessing\n",
    "3. **Zero-Shot Mask Generation** - Initial masks using SAM with bounding box prompts\n",
    "4. **Feature Extraction** - SAM encoder as feature extractor for domain adaptation\n",
    "5. **Domain Alignment** - Adversarial training for domain adaptation\n",
    "6. **Self-Training** - Iterative pseudo-labeling on target domain\n",
    "7. **Post-Processing** - CRF and morphological refinement\n",
    "8. **Validation & Inference** - Final pipeline deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db2866",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Initialization\n",
    "\n",
    "### What this step does:\n",
    "- ‚úÖ Verifies CUDA/GPU availability for accelerated training\n",
    "- ‚úÖ Checks all required dependencies (PyTorch, SAM, domain adaptation libraries)\n",
    "- ‚úÖ Sets up project directory structure\n",
    "- ‚úÖ Downloads and initializes SAM model checkpoint\n",
    "- ‚úÖ Configures logging and device settings\n",
    "\n",
    "### Key Components:\n",
    "1. **CUDA Verification**: Ensures GPU is available for training\n",
    "2. **Dependency Check**: Validates all required packages are installed\n",
    "3. **SAM Model Loading**: Downloads and loads pretrained SAM checkpoint\n",
    "4. **Directory Setup**: Creates organized folder structure for data and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cfe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('src')\n",
    "\n",
    "# Import our custom modules\n",
    "from environment_setup import EnvironmentSetup, quick_setup\n",
    "from sam_setup import SAMModelSetup, setup_sam_model\n",
    "\n",
    "print(\"=== Step 1: Environment Setup ===\")\n",
    "print(\"Initializing environment for SAM-based segmentation with domain adaptation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Environment Validation\n",
    "print(\"\\n1.1 Validating Environment...\")\n",
    "env_setup = EnvironmentSetup(log_level=\"INFO\")\n",
    "validation_results = env_setup.validate_environment()\n",
    "\n",
    "# Display results\n",
    "print(\"\\n=== Environment Validation Results ===\")\n",
    "for key, value in validation_results.items():\n",
    "    status = \"‚úÖ\" if value else \"‚ùå\" if isinstance(value, bool) else \"‚ÑπÔ∏è\"\n",
    "    print(f\"{status} {key}: {value}\")\n",
    "\n",
    "if not validation_results['overall_status']:\n",
    "    print(\"\\n‚ö†Ô∏è Please install missing dependencies using:\")\n",
    "    print(\"pip install -r requirements.txt\")\n",
    "    print(\"\\nFor SAM specifically:\")\n",
    "    print(\"pip install segment-anything\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Environment validation successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Device Configuration\n",
    "print(\"\\n1.2 Device Configuration...\")\n",
    "device_info = env_setup.get_device_info()\n",
    "\n",
    "print(\"\\n=== Device Information ===\")\n",
    "for key, value in device_info.items():\n",
    "    print(f\"üìã {key}: {value}\")\n",
    "\n",
    "# Set device for the pipeline\n",
    "device = env_setup.device\n",
    "print(f\"\\nüéØ Using device: {device}\")\n",
    "\n",
    "# Memory check for GPU\n",
    "if device.type == 'cuda':\n",
    "    import torch\n",
    "    print(f\"\\nüîã GPU Memory Status:\")\n",
    "    print(f\"   Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"   Allocated: {torch.cuda.memory_allocated() / 1e9:.3f} GB\")\n",
    "    print(f\"   Cached: {torch.cuda.memory_cached() / 1e9:.3f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 SAM Model Setup\n",
    "print(\"\\n1.3 SAM Model Initialization...\")\n",
    "\n",
    "# Initialize SAM setup\n",
    "sam_setup = SAMModelSetup(models_dir=\"models\", log_level=\"INFO\")\n",
    "\n",
    "# Display available models\n",
    "print(\"\\nüìö Available SAM Models:\")\n",
    "available_models = sam_setup.list_available_models()\n",
    "for model_type, description in available_models.items():\n",
    "    print(f\"   {model_type}: {description}\")\n",
    "\n",
    "# Choose model based on available GPU memory\n",
    "if device.type == 'cuda':\n",
    "    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    if gpu_memory_gb >= 16:\n",
    "        recommended_model = \"vit_l\"  # Large model for high-memory GPUs\n",
    "    elif gpu_memory_gb >= 8:\n",
    "        recommended_model = \"vit_b\"  # Base model for medium-memory GPUs\n",
    "    else:\n",
    "        recommended_model = \"vit_b\"  # Base model for lower-memory GPUs\n",
    "else:\n",
    "    recommended_model = \"vit_b\"  # Base model for CPU\n",
    "\n",
    "print(f\"\\nüéØ Recommended model for your setup: {recommended_model}\")\n",
    "print(f\"   {available_models[recommended_model]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeaceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SAM model\n",
    "print(f\"\\nüîÑ Loading SAM {recommended_model} model...\")\n",
    "print(\"‚ö†Ô∏è This may take a few minutes for first-time download...\")\n",
    "\n",
    "try:\n",
    "    # Load SAM model\n",
    "    sam_setup.load_sam_model(model_type=recommended_model, device=str(device))\n",
    "    \n",
    "    # Get model info\n",
    "    model_info = sam_setup.get_model_info()\n",
    "    \n",
    "    print(\"\\n‚úÖ SAM Model Successfully Loaded!\")\n",
    "    print(\"\\n=== Model Information ===\")\n",
    "    for key, value in model_info.items():\n",
    "        print(f\"üìã {key}: {value}\")\n",
    "    \n",
    "    # Test SAM predictor\n",
    "    sam_predictor = sam_setup.get_sam_predictor()\n",
    "    print(f\"\\nüéØ SAM Predictor ready: {type(sam_predictor).__name__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading SAM model: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"   1. Ensure segment-anything is installed: pip install segment-anything\")\n",
    "    print(\"   2. Check internet connection for model download\")\n",
    "    print(\"   3. Verify sufficient disk space in 'models' directory\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Project Structure Verification\n",
    "print(\"\\n1.4 Project Structure Verification...\")\n",
    "\n",
    "# Define expected directories\n",
    "project_dirs = {\n",
    "    'dataset': 'Dataset storage (source and target images)',\n",
    "    'src': 'Source code modules',\n",
    "    'models': 'Model checkpoints and weights',\n",
    "    'outputs': 'Generated masks and results',\n",
    "    'logs': 'Training and inference logs',\n",
    "    'checkpoints': 'Training checkpoints'\n",
    "}\n",
    "\n",
    "print(\"\\nüìÅ Project Directory Structure:\")\n",
    "base_path = Path.cwd()\n",
    "for dir_name, description in project_dirs.items():\n",
    "    dir_path = base_path / dir_name\n",
    "    exists = \"‚úÖ\" if dir_path.exists() else \"‚ùå\"\n",
    "    print(f\"   {exists} {dir_name}/: {description}\")\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not dir_path.exists():\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"      üîß Created directory: {dir_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Project structure setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e23b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Environment Summary\n",
    "print(\"\\n1.5 Environment Setup Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "setup_summary = {\n",
    "    \"Device\": str(device),\n",
    "    \"CUDA Available\": torch.cuda.is_available(),\n",
    "    \"SAM Model\": sam_setup.current_model_type,\n",
    "    \"Model Device\": str(model_info['device']),\n",
    "    \"PyTorch Version\": torch.__version__,\n",
    "    \"Project Ready\": \"‚úÖ YES\"\n",
    "}\n",
    "\n",
    "for key, value in setup_summary.items():\n",
    "    print(f\"üéØ {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üöÄ Environment setup complete! Ready for Step 2.\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ebddb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Step 1 Complete: Environment Setup\n",
    "\n",
    "### What was accomplished:\n",
    "1. **‚úÖ CUDA/GPU Verification** - Confirmed hardware acceleration availability\n",
    "2. **‚úÖ Dependency Validation** - Verified all required packages are installed\n",
    "3. **‚úÖ SAM Model Loading** - Downloaded and initialized pretrained SAM model\n",
    "4. **‚úÖ Directory Structure** - Created organized project folders\n",
    "5. **‚úÖ Device Configuration** - Set up optimal device settings for training\n",
    "\n",
    "### Next Step Preview: **Step 2 - Data Ingestion and Preprocessing**\n",
    "- Load source dataset images with bounding box annotations\n",
    "- Prepare target (unlabeled) dataset images\n",
    "- Implement preprocessing pipeline (resize, normalize, augment)\n",
    "- Create data loaders for efficient batch processing\n",
    "\n",
    "---\n",
    "\n",
    "**üõë CHECKPOINT**: Please confirm if everything in Step 1 is working correctly before proceeding to Step 2.\n",
    "\n",
    "**Expected outputs:**\n",
    "- All validation checks should show ‚úÖ\n",
    "- SAM model should be loaded successfully\n",
    "- Device should be properly configured (CUDA if available)\n",
    "- All project directories should be created"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
